{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhQFCIGDaxJJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbYRCUeEa8gG"
      },
      "outputs": [],
      "source": [
        "#cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sj5e0QWbNc7"
      },
      "outputs": [],
      "source": [
        "#ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsYOgAiwbjYL"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer # modelin doğruluğunu ,kaybını tespit etmek için."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrKI_LYMbrKr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from jiwer  import wer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNHkgwh6coxe"
      },
      "outputs": [],
      "source": [
        "data_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
        "data_path = keras.utils.get_file('LJSpeech-1.1', data_url, untar = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQJAxT3SeDf9"
      },
      "outputs": [],
      "source": [
        "wavs_path = data_path + \"/wavs/\"\n",
        "metadata_path = data_path + \"/metadata.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPU_E1CggOgJ"
      },
      "outputs": [],
      "source": [
        "metadata_df = pd.read_csv(metadata_path, sep= \"|\", header = None, quoting= 3 )\n",
        "metadata_df.head(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N29xywI4hr77"
      },
      "outputs": [],
      "source": [
        "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
        "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
        "metadata_df = metadata_df.sample(frac = 1).reset_index(drop = True)\n",
        "metadata_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3JZ-73MjBBj"
      },
      "outputs": [],
      "source": [
        "#datasetimizin train ve validationa bölünmesi\n",
        "split = int(len(metadata_df)  * 0.9)\n",
        "df_train = metadata_df[:split]\n",
        "df_val = metadata_df[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2BXq8vPnSSr"
      },
      "outputs": [],
      "source": [
        "#alfabe karaketerlerinin tanımlandırılması ve sayısallaşitırılması\n",
        "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!\"]\n",
        "\n",
        "#keras.layers.StringLookup sınıfı, bir sözlüğü oluşturmak ve bir dizi karakteri sayısal değerlere dönüştürmek için kullanılır.\n",
        "\n",
        "#vocabulary parametresi, sözlükteki benzersiz karakterlerin listesini içerir. \n",
        "#oov_token parametresi, sözlükte bulunmayan karakterler için bir yer tutucu değer belirler.\n",
        "char_to_num = keras.layers.StringLookup(vocabulary = characters, oov_token=\"\")\n",
        " \n",
        "#Bu nesne, karakter dizisindeki her bir karakterin sayısal değerini içeren bir sözlüğü temsil eder.\n",
        "num_to_char = keras.layers.StringLookup(vocabulary = char_to_num.get_vocabulary(),\n",
        "                                        oov_token=\"\", invert = True)\n",
        "\n",
        "print(f\"Vocabulary: {char_to_num.get_vocabulary()}\"\n",
        "      f\"(size= {char_to_num.vocabulary_size()})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WrtEa11oTCC"
      },
      "outputs": [],
      "source": [
        "frame_length = 256\n",
        "frame_step = 160\n",
        "fft_length = 384\n",
        "\n",
        "def encode_single_sample(wav_file, label):\n",
        "    file = tf.io.read_file(wavs_path + wav_file + \".wav\") # ses dosyasının okunma işlemi\n",
        "\n",
        "    audio, _ = tf.audio.decode_wav(file)  #Ses dosyası çözümlenir\n",
        "    audio = tf.squeeze(audio, axis=-1) #tekrar eden değerlerin atılması\n",
        "\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "\n",
        "    #Bu fonksiyon, kısa süreli Fourier dönüşümü (STFT) uygulayarak, ses sinyalini frekans-zaman uzayında temsil eden bir spektrogram oluşturur.\n",
        "    #STFT (Short-Time Fourier Transform), bir ses sinyalinin frekans bileşenlerini zamana göre analiz etmek için kullanılan bir matematiksel işlemdir. \n",
        "    #STFT, uzun bir ses sinyalini küçük parçalara bölerek, her bir parçanın spektrogramını hesaplar\n",
        "    spectrogram = tf.signal.stft( audio, frame_length = frame_length, \n",
        "                                 frame_step = frame_step, fft_length = fft_length)\n",
        "    \n",
        "    #Normalize işlemleri\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "\n",
        "    means = tf.math.reduce_mean(spectrogram, 1, keepdims = True)\n",
        "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims = True)\n",
        "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "    label = tf.strings.lower(label) #Etiketler küçük harfe çevrilir \n",
        "\n",
        "    #fonksiyonu ile Unicode kodlama standardına göre ayrıştırılır. Bu işlem, etiketteki her bir karakterin sayısal bir değere dönüştürülmesi için gereklidir.\n",
        "    label = tf.strings.unicode_split(label, input_encoding = \"UTF-8\") \n",
        "\n",
        "    #7.\tKarakterleri sayısal değerlere dönüştürmek için char_to_num fonksiyonu çağrılır. Bu fonksiyon, etiketlerdeki her bir karakteri, karakter kümesindeki sırasına göre bir sayıya dönüştürür\n",
        "    label = char_to_num(label)\n",
        "\n",
        "    return spectrogram, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7dN_KyLuAMJ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_train[\"file_name\"]), list(df_train[\"normalized_transcription\"])) )\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_val[\"file_name\"]), list (df_val[\"normalized_transcription\"])) )\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLJ2XYvqw5Jy"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 5))\n",
        "for batch in train_dataset.take(1):  #yöntemi, eğitim veri kümesinden sadece bir örnek alır.\n",
        "    spectrogram = batch[0][0].numpy()\n",
        "    spectrogram = np.array([np.trim_zeros(x) for x in np.transpose(spectrogram)])\n",
        "    label = batch[1][0]\n",
        "    # Spectrogram\n",
        "    label = tf.strings.reduce_join(num_to_char(label)). numpy().decode(\"utf-8\") #burada sayısal etiketler karakterlere dönüştürür.\n",
        "    ax = plt.subplot(2, 1, 1)\n",
        "    ax.imshow(spectrogram, vmax=1)\n",
        "    ax.set_title(label)\n",
        "    ax.axis (\"off\")\n",
        "    \n",
        "    # Wav\n",
        "    # İkinci grafik, ses sinyali dalga formunu gösterir. \n",
        "    file = tf.io.read_file(wavs_path + list (df_train[\"file_name\"])[0] + \".wav\") \n",
        "    audio, _ = tf.audio.decode_wav(file) #bu yöntem, ses dosyasını çözümler ve dalga formu ve örnekleme sıklığı gibi bilgileri içeren bir tensör döndürür.\n",
        "    audio = audio.numpy()\n",
        "    ax = plt.subplot(2, 1, 2)\n",
        "    plt.plot(audio)\n",
        "    ax.set_title(\"Signal Wave\")\n",
        "    ax.set_xlim (0, len (audio))\n",
        "    display.display (display.Audio (np.transpose (audio), rate=16000))# Bu yöntem, ses sinyalini dinlemek için bir ses öğesi oluşturur. Audio() sınıfı, NumPy dizisini ve örnekleme sıklığını alır ve bir ses öğesi oluşturur.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpjGCRah0lOZ"
      },
      "outputs": [],
      "source": [
        "def CTCLoss (y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    #Bu yöntem, CTC kaybını hesaplar. Bu yöntem, y_true, y_pred, input_length ve label_length tensörlerini alır ve CTC kaybını döndürür.\n",
        "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss #loss değişkeni, CTC kaybını içeren bir tensördür.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88nj61EO1OE4"
      },
      "outputs": [],
      "source": [
        "def build_model(input_dim, output_dim, rnn_layers = 5, rnn_units = 128):\n",
        "  \n",
        "  #\tinput_dim parametresi, girdi spektrogramının boyutunu belirtir.\n",
        "  #\toutput_dim parametresi, modelin çıkış boyutunu belirtir.\n",
        "  #\trnn_layers parametresi, modeldeki RNN (Recurrent Neural Network) katmanları sayısını belirtir. Varsayılan değeri 5'tir.\n",
        "  #\trnn_units parametresi, RNN katmanlarındaki birim sayısını belirtir. Varsayılan değeri 128'dir.\n",
        "  \n",
        "\n",
        "    input_spectrogram = layers.Input((None, input_dim), name = 'input') \n",
        "\n",
        "    x = layers.Reshape((-1, input_dim, 1), name = \"expand_dim\")(input_spectrogram)\n",
        "\n",
        "    #1ci convolusyon katmani\n",
        "    x = layers.Conv2D(filters = 32, kernel_size = [11, 41], strides = [2, 2], \n",
        "                      padding =\"same\", use_bias = False, name = \"conv_1\" )(x)\n",
        "    x = layers.BatchNormalization(name = \"conv_1_bn\")(x)\n",
        "    x = layers.ReLU(name = \"conv_1_relu\")(x)\n",
        "    \n",
        "    #2ci convolusyon katmani\n",
        "    x = layers.Conv2D(filters = 32, kernel_size = [11, 21], strides = [1, 2], \n",
        "                      padding =\"same\", use_bias = False, name = \"conv_2\" )(x)\n",
        "    x = layers.BatchNormalization(name = \"conv_2_bn\")(x)          # evrişimli sinir ağı katmanlarındakiağırlıkları normalize eder.\n",
        "    x = layers.ReLU(name = \"conv_2_relu\")(x)                      # evrişimli sinir ağı katmanlarındaki aktivasyon fonksiyonunu tanımlar.\n",
        "\n",
        "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)        # tensörün şeklini yeniden şekillendirir.\n",
        "\n",
        "    for i in range(1, rnn_layers + 1):\n",
        "      #yöntemi, RNN katmanını tanımlar.\n",
        "        recurrent = layers.GRU(units = rnn_units, activation = \"tanh\", recurrent_activation= \"sigmoid\", \n",
        "                               use_bias = True, return_sequences = True, reset_after = True, name = f\"gru_{i}\")\n",
        "        x = layers.Bidirectional(recurrent, name = f\"bidirectional_{i}\", merge_mode = \"concat\" )(x)\n",
        "        if i<rnn_layers:\n",
        "            x = layers.Dropout(rate = 0.5)(x)\n",
        "    #Dense Layer\n",
        "    x = layers.Dense(units = rnn_units * 2, name = \"dense_1\")(x)  # modelin yoğun katmanını tanımlar.\n",
        "    x = layers.ReLU(name = \"dense_1_relu\")(x)                     # evrişimli sinir ağı katmanlarındaki aktivasyon fonksiyonunu tanımlar.\n",
        "    x = layers.Dropout(rate = 0.5)(x)\n",
        "\n",
        "    #classification layer\n",
        "    output = layers.Dense(units = output_dim + 1, activation = \"softmax\")(x)\n",
        "    #model\n",
        "    model = keras.Model(input_spectrogram, output, name = \"DeepSpeech_2\") # girdi ve çıktı tensörlerini kullanarak modeli oluşturur.\n",
        "    #optimizer\n",
        "    opt = keras.optimizers.Adam(learning_rate = 1e-4)                     # optimize ediciyi tanımlar.\n",
        "    #compile the model and return\n",
        "    model.compile(optimizer = opt, loss= CTCLoss)                         # modeli derler ve kayıp fonksiyonunu belirler.\n",
        "    return model\n",
        "\n",
        "#get the model\n",
        "model = build_model(input_dim = fft_length // 2 + 1,\n",
        "                    output_dim = char_to_num.vocabulary_size(), \n",
        "                    rnn_units = 521)\n",
        "model.summary(line_length = 110)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_dXMIFl9xwO"
      },
      "outputs": [],
      "source": [
        "#pred parametresi, modelin tahminlerini içeren bir numpy dizisidir.\n",
        "def decode_batch_predictions (pred):                  #decode_batch_predictions() fonksiyonu, modelin çıktısını çözümlemek için kullanılır.\n",
        "    input_len = np.ones (pred.shape[0]) * pred.shape[1]\n",
        "    \n",
        "    # Use greedy search. For complex tasks, you can use beam search \n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True) [0][0] # Iterate over the results and get back the text \n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\") \n",
        "        output_text.append(result)\n",
        "    return output_text\n",
        "\n",
        "class CallbackEval(keras.callbacks.Callback): \n",
        "    def __init__(self, dataset): \n",
        "        super().__init__() \n",
        "        self.dataset = dataset\n",
        "\n",
        "    def on_epoch_end (self, epoch: int, logs=None): \n",
        "        predictions = [] \n",
        "        targets = [] \n",
        "        for batch in self.dataset:\n",
        "            X, y = batch\n",
        "            batch_predictions = model.predict(X)\n",
        "            batch_predictions = decode_batch_predictions(batch_predictions) \n",
        "            predictions.extend(batch_predictions)\n",
        "\n",
        "        for label in y:\n",
        "            label = ( tf.strings.reduce_join(num_to_char (label)).numpy().decode(\"utf-8\"))\n",
        "            targets.append(label)\n",
        "\n",
        "        wer_score = wer(targets, predictions)\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "        print(\"-\" * 100)\n",
        "        for i in np.random.randint(0, len(predictions), 2):\n",
        "            print(f\"Target : {targets[i]}\")\n",
        "            print(f\"Prediction: {predictions[i]}\")\n",
        "            print(\"_\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzAkhBT7A9Km"
      },
      "outputs": [],
      "source": [
        "epochs =2 \n",
        "\n",
        "validation_callback = CallbackEval(validation_dataset)\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs = epochs,\n",
        "    callbacks=[validation_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P30K-PkXFand"
      },
      "outputs": [],
      "source": [
        "!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "from googletrans import Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IymvHL7ZBetW"
      },
      "outputs": [],
      "source": [
        "predictions = [] \n",
        "targets = [] \n",
        "for batch in validation_dataset:\n",
        "    X, y = batch\n",
        "    batch_predictions = model.predict(X)\n",
        "    batch_predictions = decode_batch_predictions(batch_predictions) \n",
        "    predictions.extend(batch_predictions)\n",
        "\n",
        "    for label in y:\n",
        "        label = ( tf.strings.reduce_join(num_to_char (label)).numpy().decode(\"utf-8\"))\n",
        "        targets.append(label)\n",
        "\n",
        "wer_score = wer(targets, predictions)\n",
        "print(\"-\" * 100)\n",
        "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "print(\"-\" * 100)\n",
        "for i in np.random.randint(0, len(predictions), 2):\n",
        "    print(f\"Target : {targets[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")\n",
        "    print(\"_\"*100)\n",
        "        \n",
        "    translator = Translator()\n",
        "\n",
        "    #İngilizce bir metni Türkçe'ye çevirme\n",
        "    text = \n",
        "    result = translator.translate(text, src='en', dest='tr')\n",
        "\n",
        "    print(result.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v_oJU_Vrp6sS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}